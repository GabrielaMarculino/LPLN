{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGKnRMiPT8eu3n+xoi16cM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielaMarculino/LPLN/blob/main/C%C3%B3pia_de_aula_01LPLN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 01 - Expressão Regular\n",
        "##Introdução à Processamento de Linguagem Natural\n"
      ],
      "metadata": {
        "id": "CE-rKLw7C-c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re # biblioteca utilizada para definir expressões regulares\n",
        "\n",
        "poema = \"\"\"Ainda que mal\n",
        "\n",
        "Ainda que mal pergunte,\n",
        "ainda que mal respondas;\n",
        "ainda que mal te entenda,\n",
        "ainda que mal repitas;\n",
        "ainda que mal insista,\n",
        "ainda que mal desculpes;\n",
        "ainda que mal me exprima,\n",
        "ainda que mal me julgues;\n",
        "ainda que mal me mostre,\n",
        "ainda que mal me vejas;\n",
        "ainda que mal te encare,\n",
        "ainda que mal te furtes;\n",
        "ainda que mal te siga,\n",
        "ainda que mal te voltes;\n",
        "ainda que mal te ame,\n",
        "ainda que mal o saibas;\n",
        "ainda que mal te agarre,\n",
        "ainda que mal te mates;\n",
        "ainda assim te pergunto\n",
        "e me queimando em teu seio,\n",
        "me salvo e me dano;\"\"\"\n",
        "\n",
        "re.findall(r\"mal\", poema) # método findall retorna todas as ocorrências de um padrão numa determinada string\n",
        "\n",
        "# len(re.findall(r\"mal\", poema))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l7dkceaDBBR",
        "outputId": "b7c6d31b-14aa-4de8-b892-2b96a698a023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 2 - Disjunção"
      ],
      "metadata": {
        "id": "O8Nthh5zFjtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re # biblioteca utilizada para definir expressões regulares\n",
        "\n",
        "poema = \"\"\"Ainda que mal\n",
        "\n",
        "Ainda que mal pergunte,\n",
        "ainda que mal respondas;\n",
        "ainda que mal te entenda,\n",
        "ainda que mal repitas;\n",
        "ainda que mal insista,\n",
        "ainda que mal desculpes;\n",
        "ainda que mal me exprima,\n",
        "ainda que mal me julgues;\n",
        "ainda que mal me mostre,\n",
        "ainda que mal me vejas;\n",
        "ainda que mal te encare,\n",
        "ainda que mal te furtes;\n",
        "ainda que mal te siga,\n",
        "ainda que mal te voltes;\n",
        "ainda que mal te ame,\n",
        "ainda que mal o saibas;\n",
        "ainda que mal te agarre,\n",
        "ainda que mal te mates;\n",
        "ainda assim te pergunto\n",
        "e me queimando em teu seio,\n",
        "me salvo e me dano;\"\"\"\n",
        "\n",
        "re.findall(r\"[Aa]inda que mal\", poema) # método findall retorna todas as ocorrências de um padrão numa determinada string\n",
        "             # [Aa] - disjunção\n",
        "# len(re.findall(r\"[Aa]inda que mal\", poema))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDv2L9klFoWP",
        "outputId": "09c3df39-25ec-41f1-f72a-abdf2f819089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ainda que mal',\n",
              " 'Ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal',\n",
              " 'ainda que mal']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KN2i4Mvuy5vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 3 - Disjunção e intervalos"
      ],
      "metadata": {
        "id": "zwekgkDrG5-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "descricao = \"\"\"Monitor LG 19.5'' LED HD - HDMI, 2ms, Ajuste de Inclinação, Reader Mode, 4-Screen Split, - 20MK400H-B\"\"\"\n",
        "\n",
        "re.findall(r\"[0-4]\", descricao)\n",
        "\n",
        "# len(re.findall(r\"[0-4]\", descricao))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsbryMu5HAbN",
        "outputId": "02315e78-1c54-4b2e-d483-bf67f63b46bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', '2', '4', '2', '0', '4', '0', '0']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 4 - Negação na Disjunção"
      ],
      "metadata": {
        "id": "xVpzuhcqIAHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "poema = \"\"\"Quando Ismália enlouqueceu,\n",
        "Pôs-se na torre a sonhar…\n",
        "Viu uma lua no céu,\n",
        "Viu outra lua no mar.\n",
        "\n",
        "No sonho em que se perdeu,\n",
        "Banhou-se toda em luar…\n",
        "Queria subir ao céu,\n",
        "Queria descer ao mar…\n",
        "\n",
        "E, no desvario seu,\n",
        "Na torre pôs-se a cantar…\n",
        "Estava perto do céu,\n",
        "Estava longe do mar…\n",
        "\n",
        "E como um anjo pendeu\n",
        "As asas para voar…\n",
        "Queria a lua do céu,\n",
        "Queria a lua do mar…\n",
        "\n",
        "As asas que Deus lhe deu\n",
        "Ruflaram de par em par…\n",
        "Sua alma subiu ao céu,\n",
        "Seu corpo desceu ao mar…\"\"\"\n",
        "\n",
        "re.findall(r\"[^a-z]\", poema) # todos os elementos exceto caracteres em letra maiúscula"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUYsuT_mIEXb",
        "outputId": "0b04204f-9d3f-42b0-859b-5449950f88be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Q',\n",
              " ' ',\n",
              " 'I',\n",
              " 'á',\n",
              " ' ',\n",
              " ',',\n",
              " '\\n',\n",
              " 'P',\n",
              " 'ô',\n",
              " '-',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '…',\n",
              " '\\n',\n",
              " 'V',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " 'é',\n",
              " ',',\n",
              " '\\n',\n",
              " 'V',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '.',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'N',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ',',\n",
              " '\\n',\n",
              " 'B',\n",
              " '-',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '…',\n",
              " '\\n',\n",
              " 'Q',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " 'é',\n",
              " ',',\n",
              " '\\n',\n",
              " 'Q',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '…',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'E',\n",
              " ',',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ',',\n",
              " '\\n',\n",
              " 'N',\n",
              " ' ',\n",
              " ' ',\n",
              " 'ô',\n",
              " '-',\n",
              " ' ',\n",
              " ' ',\n",
              " '…',\n",
              " '\\n',\n",
              " 'E',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " 'é',\n",
              " ',',\n",
              " '\\n',\n",
              " 'E',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '…',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'E',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '\\n',\n",
              " 'A',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '…',\n",
              " '\\n',\n",
              " 'Q',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " 'é',\n",
              " ',',\n",
              " '\\n',\n",
              " 'Q',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '…',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'A',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " 'D',\n",
              " ' ',\n",
              " ' ',\n",
              " '\\n',\n",
              " 'R',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '…',\n",
              " '\\n',\n",
              " 'S',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " 'é',\n",
              " ',',\n",
              " '\\n',\n",
              " 'S',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '…']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 5 - Múltiplos Padrões de Busca"
      ],
      "metadata": {
        "id": "IqnLi-doKNOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "poema = \"\"\"No meio do caminho tinha uma pedra\n",
        "tinha uma pedra no meio do caminho\n",
        "tinha uma pedra\n",
        "no meio do caminho tinha uma pedra.\n",
        "\n",
        "Nunca me esquecerei desse acontecimento\n",
        "na vida de minhas retinas tão fatigadas.\n",
        "Nunca me esquecerei que no meio do caminho\n",
        "tinha uma pedra\n",
        "tinha uma pedra no meio do caminho\n",
        "no meio do caminho tinha uma pedra.\"\"\"\n",
        "\n",
        "re.findall(r\"pedra|[Tt]inha\", poema)  # busca todas as combinações de tinha e pedra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S54UZUtDKXVl",
        "outputId": "178043a8-f318-4722-b41f-4b1eace7432b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tinha',\n",
              " 'pedra',\n",
              " 'tinha',\n",
              " 'pedra',\n",
              " 'tinha',\n",
              " 'pedra',\n",
              " 'tinha',\n",
              " 'pedra',\n",
              " 'tinha',\n",
              " 'pedra',\n",
              " 'tinha',\n",
              " 'pedra',\n",
              " 'tinha',\n",
              " 'pedra']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 6 - Quantificadores"
      ],
      "metadata": {
        "id": "ehRlUGacOPkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "caso = \"\"\"Pode checar a conta ABC4323?\n",
        "          Emitir segunda via do boleto de Dezembro da conta YIC9834.\n",
        "          Meu nome é Gabriela, portador da conta NHD8432. Quantos créditos tenho?\"\"\"\n",
        "\n",
        "re.findall(r\"\\b[A-Z]{3}[0-9]{4}\\b\", caso) # filtra tudo que tem sequência de 3 letras maiúsculas e 4 números de 0 à 9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eMHgcrIOUzb",
        "outputId": "dc778f9e-0b11-43b6-a1fe-41f9e35e4c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ABC4323', 'YIC9834', 'NHD8432']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercicio: Como retornar os padrões de risos em mensagens de redes sociais? Como: Hahahaha | Huahuahua | Haha | KKK"
      ],
      "metadata": {
        "id": "f3DKfrSsQs5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "expressoes = \"\"\"Hahahahaha\n",
        "                Huahuahuahua\n",
        "                Haha\n",
        "                kkkkk\"\"\"\n",
        "\n",
        "p = re.compile(r\"k+|([Hh|a])+|([Hh|ua])+\") # Podemos combinar uma expressão regular com objetos de padrões, que pode ser usado para encontrar padrões.\n",
        "iterador = p.finditer(expressoes) # encontra todas as substrings que têm correspondência com a expressão regular, e as retorna como um iterador\n",
        "\n",
        "for i in iterador:\n",
        "  inicio, fim = i.span() #  forma bem útil e eficiente para coletar informações em strings, encontrar padrões de textos\n",
        "  print(inicio, fim, expressoes[inicio:fim])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfd-aNuVQ_Sz",
        "outputId": "ceea4694-18b1-4160-a57d-1426392a9f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 10 Hahahahaha\n",
            "27 28 H\n",
            "28 39 uahuahuahua\n",
            "56 60 Haha\n",
            "77 82 kkkkk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 7 - Substituição"
      ],
      "metadata": {
        "id": "hPEjlG_1pdRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "texto = \"\"\"Reconheço que tomei decisões insatisfatórias recentemente, mas posso lhe garantir com absoluta certreza que meu trabalho voltará ao normal.\"\"\"\n",
        "\n",
        "re.sub(r'[,;.!\\n]','',texto) # substitui todos os parâmetros por um caractere vazio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cPPAf0Bjpirc",
        "outputId": "2c0ad368-3307-4ff5-b1aa-4714ef6914cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Reconheço que tomei decisões insatisfatórias recentemente mas posso lhe garantir com absoluta certreza que meu trabalho voltará ao normal'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 8 - Memória"
      ],
      "metadata": {
        "id": "-potOVsEqZZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "texto = \"\"\"Reconheço que tomei decisões insatisfatórias recentemente, mas posso lhe garantir com absoluta certreza que meu trabalho voltará ao normal.\"\"\"\n",
        "\n",
        "print(re.sub(r'([,;.!?:])',r' \\1', texto)) # adiciona um espaço entre as pontuações"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i-YB88vqc--",
        "outputId": "8a42a31c-4a2b-4169-ee67-60a83df57bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconheço que tomei decisões insatisfatórias recentemente , mas posso lhe garantir com absoluta certreza que meu trabalho voltará ao normal .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo - Distância de Edição"
      ],
      "metadata": {
        "id": "ttk00xJCw3qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics import *  # estabelece uma infraestrutura que pode ser utilizada para criar programas de NLP\n",
        "\n",
        "\n",
        "a = \"Bello Horizonte\"\n",
        "b = \"Belo Horizonte\"\n",
        "\n",
        "distancia = edit_distance(a,b)\n",
        "\n",
        "print(\"A distância de Levenstein entre \", a, \"e\", b, \"é igual a\", distancia)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjApu7zQw-mU",
        "outputId": "a13be8ca-9a8f-44f8-a863-84050bad4744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A distância de Levenstein entre  Bello Horizonte e Belo Horizonte é igual a 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo - Tokenização"
      ],
      "metadata": {
        "id": "9A3wHTmt3II5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import tokenize\n",
        "\n",
        "versos = \"\"\"No meio do caminho tinha uma pedra\n",
        "            Tinha uma pedra no meio do caminho\"\"\" # lembrar de falar da letra maiuscula/minuscula\n",
        "\n",
        "palavras = tokenize.word_tokenize(versos, language='portuguese')\n",
        "\n",
        "print(len(palavras), palavras, '\\n', len(set(palavras)), set(palavras))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STN7bFub3MbB",
        "outputId": "d40d158f-5219-432a-a8e7-5dc52e6bdd1e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 ['No', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', 'Tinha', 'uma', 'pedra', 'no', 'meio', 'do', 'caminho'] \n",
            " 9 {'Tinha', 'pedra', 'uma', 'caminho', 'do', 'meio', 'tinha', 'no', 'No'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo de Capitalização"
      ],
      "metadata": {
        "id": "kruJVVAh4TeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import tokenize\n",
        "\n",
        "versos = \"\"\"No meio do caminho tinha uma pedra\n",
        "            Tinha uma pedra no meio do caminho\"\"\"\n",
        "\n",
        "palavras = tokenize.word_tokenize(versos.lower(), language='portuguese')\n",
        "                                  # transformando todos os caracteres em minusculo\n",
        "\n",
        "print(len(palavras), palavras, '\\n', len(set(palavras)), set(palavras))\n",
        "\n",
        "# essa etapa é importante e muito aplicada, entretanto temos que ir com cautela pois dependendo da situação essa etapa atrapalha, pois\n",
        "# imagine a seguinte problemática: utilizamos o prefixo (se) joao fosse à escola e no mesmo contexto\n",
        "# estivéssimos usando a sigla (SE) para nos referir a Sergipe, esse tratamento de dados seria totalmente erroneo!"
      ],
      "metadata": {
        "id": "1L9w-pFf4XFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo de Lematização"
      ],
      "metadata": {
        "id": "7PsK5seqFqJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download das bibliotecas\n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!pip install -U spacy-lookups-data\n",
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "id": "mjlQlBXeG6pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy # transforma dados / tokenização\n",
        "\n",
        "pln = spacy.load('pt_core_news_sm')\n",
        "\n",
        "frase = pln(\"A comida estava gostosa. Todos comeram e gostaram.\")\n",
        "\n",
        "lemas = []\n",
        "\n",
        "for token in frase:\n",
        "  lema = token.lemma_\n",
        "  lemas.append(lema)\n",
        "\n",
        "print(lemas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVe3MTTyFvUg",
        "outputId": "c8dc339e-4e89-41d3-9322-078191df99d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['o', 'comida', 'estar', 'gostoso', '.', 'todo', 'comer', 'e', 'gostar', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo de Radicalização - Stemming"
      ],
      "metadata": {
        "id": "qG-yeJ8mHNbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download da biblioteca\n",
        "nltk.download('rslp')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwTGJuSQHQ1F",
        "outputId": "4072fbbf-ff6d-43b8-b971-e16b04ef47f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "raiz = nltk.stem.RSLPStemmer()\n",
        "\n",
        "print(raiz.stem(\"a\"),\n",
        "raiz.stem(\"comida\"),\n",
        "raiz.stem(\"estava\"),\n",
        "raiz.stem(\"gostosa\"),\n",
        "raiz.stem(\"todos\"),\n",
        "raiz.stem(\"comeram\"),\n",
        "raiz.stem(\"e\"),\n",
        "raiz.stem(\"gostaram\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYm99iKuHbzW",
        "outputId": "2ef104d4-9ea0-4e97-8567-e1914a82e83f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a com est gost tod com e gost\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo - Segmentação de Frases"
      ],
      "metadata": {
        "id": "CAocE8uNKYB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download da biblioteca\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVGxZp9DKi5i",
        "outputId": "c7b7f211-7184-4598-df2e-43e819c1033d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "frases = nltk.data.load(\"tokenizers/punkt/portuguese.pickle\")\n",
        "\n",
        "citacao_darcy = \"\"\" Fracassei em tudo o que tentei na vida. Tentei alfabetizar as crianças brasileiras, não consegui.\n",
        "Tentei salvar os índios, não consegui. Tentei fazer uma universidade séria e fracassei.\n",
        "Tentei fazer o Brasil desenvolver-se automaticamente e fracassei. Mas os fracassos são minhas vitórias.\n",
        "Eu detestaria estar no lugar de quem me venceu\"\"\"\n",
        "\n",
        "frases.tokenize(citacao_darcy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovN9AN-SKdTH",
        "outputId": "ab283695-8af2-45a4-cb09-20f56ba34d3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Fracassei em tudo o que tentei na vida.',\n",
              " 'Tentei alfabetizar as crianças brasileiras, não consegui.',\n",
              " 'Tentei salvar os índios, não consegui.',\n",
              " 'Tentei fazer uma universidade séria e fracassei.',\n",
              " 'Tentei fazer o Brasil desenvolver-se automaticamente e fracassei.',\n",
              " 'Mas os fracassos são minhas vitórias.',\n",
              " 'Eu detestaria estar no lugar de quem me venceu']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementação completa"
      ],
      "metadata": {
        "id": "uWn7NO0MfzVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baixando a versão 3.5 do NLTK"
      ],
      "metadata": {
        "id": "I4Po_Y-bf8Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install nltk == 3.5"
      ],
      "metadata": {
        "id": "Wm7odkDcgK81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importando dependências"
      ],
      "metadata": {
        "id": "07ja2zawgQWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "EeWKuHWdgStv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Passo 1: Carregando Córpus"
      ],
      "metadata": {
        "id": "GCl1-_MKgaIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"\"\"No meio do caminho tinha uma pedra\n",
        "Tinha uma pedra no meio do caminho\n",
        "Tinha uma pedra\n",
        "No meio do caminho tinha uma pedra\"\"\"\n",
        "\n",
        "texto = texto.lower().split('\\n')"
      ],
      "metadata": {
        "id": "NHQ1U4oAgeqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Passo 2: Tokenizando as Sentenças dos corpos"
      ],
      "metadata": {
        "id": "gdtD49Iog0Hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_tok = []\n",
        "\n",
        "for verso in texto:\n",
        "  tokens = nltk.word_tokenize(verso, language = 'portuguese')\n",
        "  texto_tok.append(tokens)\n",
        "\n",
        "  texto_tok"
      ],
      "metadata": {
        "id": "K9DYvkn9g4sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Passo 3: Pré-processando sentenças"
      ],
      "metadata": {
        "id": "DGTnVlvFhRFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "\n",
        "ngramas = 2\n",
        "\n",
        "texto_tok_pad = []\n",
        "for verso in texto_tok:\n",
        "  padded = list(pad_both_ends(verso, n = ngramas))\n",
        "  texto_tok_pad.append(padded)\n",
        "\n",
        "texto_tok_pad"
      ],
      "metadata": {
        "id": "QZNldJUUhU86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Passo 4: Calculando os N-Gramas"
      ],
      "metadata": {
        "id": "djSXWnyYhyS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngramas = 2\n",
        "\n",
        "bigramas_pad = []\n",
        "for verso in texto_tok_pad:\n",
        "  bigramas = list(nltk.ngrama(verso, n = ngramas))\n",
        "  bigramas_pad.append(bigramas)"
      ],
      "metadata": {
        "id": "E7aAaSSUh2cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#calculando unigramas além dos bigramas"
      ],
      "metadata": {
        "id": "266SrLKviwhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import everygrams\n",
        "\n",
        "ngramas = 2\n",
        "ngramas_pad = []\n",
        "\n",
        "for verso in texto_tok_pad:\n",
        "  ngramas = list(everygrams(verso, max_len=ngramas))\n",
        "  ngramas_pad.append(ngramas)\n",
        "\n",
        "ngramas_pad"
      ],
      "metadata": {
        "id": "a2rFDivii1F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Passo 5: Colocando todos os tokens do córpus numa única lista"
      ],
      "metadata": {
        "id": "0myuDaXJif9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm.preprocessing import flatten\n",
        "\n",
        "tokens = list(flatten(texto_tok_pad))\n",
        "tokens"
      ],
      "metadata": {
        "id": "Gb14d1YAjqfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Passo 6: Definindo Vocabulário"
      ],
      "metadata": {
        "id": "7O2qiQltkEGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm import Vocabulary\n",
        "\n",
        "vocab = Vocabulary(tokens, unk_cutoff=1)"
      ],
      "metadata": {
        "id": "TvlUfUsckHR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#procurando uma palavra no vocabulário"
      ],
      "metadata": {
        "id": "pMqRwYncklf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.lookup(\"caminho\")"
      ],
      "metadata": {
        "id": "eq8fMdoNkqsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#obtendo as frequências das palavras do córpus com o comando counts"
      ],
      "metadata": {
        "id": "rSKf0Fm_k1FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "1fVHqFnmkdEL",
        "outputId": "078fcdb0-6eff-4885-eefa-a7714fc6da19"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-45d988af22ba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#simplificando o pré-processamento"
      ],
      "metadata": {
        "id": "J2fTK7Eqk9xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "ngramas = 2\n",
        "\n",
        "ngramas_pad, vocab = padded_everygram_pipeline(ngramas, texto_tok)"
      ],
      "metadata": {
        "id": "9haSHMNMlAa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Passo 7: Treinando um modelo de lingugem"
      ],
      "metadata": {
        "id": "CDns_uNolTgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm import MLE\n",
        "\n",
        "ngramas = 2\n",
        "lm = MLE(ngramas)\n",
        "lm.fit(ngramas_pad, vocab)"
      ],
      "metadata": {
        "id": "tveJHhS3lZhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dado o tokes <s>, gerando um texto de 4 tokens com o modelo de linguegem treinado"
      ],
      "metadata": {
        "id": "8yu62oUAlpa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm.generate(4, text_seed = [\"<s>\"])"
      ],
      "metadata": {
        "id": "fm6lMPhrlxAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#probabilidade da palavra no:"
      ],
      "metadata": {
        "id": "53V9n98bmAEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm.score(\"no\"), lm.logscore(\"no\")"
      ],
      "metadata": {
        "id": "kmCw5UaFmCwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#probabilidade da palavra tinha dado a palavra caminho:"
      ],
      "metadata": {
        "id": "uObkDQktmQ2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm.score(\"tinha\", context = ['caminho']), lm.logscore(\"tinha\", context=[\"caminho\"])"
      ],
      "metadata": {
        "id": "O51LKAI-mYVP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}